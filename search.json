[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "solverism-quarto-blog",
    "section": "",
    "text": "news\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nOct 19, 2022\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nOct 16, 2022\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2022-09-20-tesco-price-analysis.html",
    "href": "posts/2022-09-20-tesco-price-analysis.html",
    "title": "solverism-quarto-blog",
    "section": "",
    "text": "“Measuring food price inflation in a way that anyone in the UK can relate to.”\n\n\ntoc: true\ncomments: false\nauthor: Brandon Lee\ncategories: [inflation, analysis, visualisation]\nimage: images/inflation_post.jpg\n\n\n\nDisclaimer: The use of data collected for this study is covered by the Intellectual Property Office’s Exceptions to Copyright for Non-Commercial Research and Private Study (https://www.gov.uk/guidance/exceptions-to-copyright). No personal information has been collected as part of this study’s data collection process and web scraping best practices implemented to the best of the author’s abilities. The collected data will be inaccessible to the public to abide by Section 7 of the Terms and Conditions agreement laid out by Tesco (https://www.tesco.com/help/terms-and-conditions/).\nSince July 2021 the Consumer Prices Index (CPI) inflation rate in the UK has broken away from the Bank of England’s target rate of 2%, steadily rising month by month. As of 3rd September 2022, the inflation rate stands at 10.1% with no indication of decreasing. What an awfully depressing way to start a blog post but unfortunately this is the reality that we are all currently facing in the UK. Every month the Office for National Statistics (ONS) calculates CPI by collecting the prices for a basket of around 730 different consumer goods and services that is a representation of the society’s current buying habits and measures the average change in price of the basket on a year-over-year basis. At a risk of grossly simplifying, CPI tells us how much prices in general have changed over the last 12 months.\n\nThat’s all nice and well but society’s buying habits doesn’t necessarily reflect my buying habits. There are 12 broad categories of goods and services in the CPI basket, some of these categories such as clothing and footwear, and furniture and household goods don’t apply to me as I rarely ever buy new clothes or furniture. The full list of categories and goods and services of each category can be found on the ONS website here. One category that does apply to me, and to everyone else, is food and drinks. Food and drink goods (excluding alcohol) currently account for 9.3% of the weighting in CPI, which is a relatively small slice of the pie.\nDuring recent times I’ve noticed that my shopping bill has gone up overall but I can’t quite pin down what items are contributing the most to this increase. To this end, I’ve built a cloud-based web-scraping application that scrapes product data from Tesco’s website including price and categories (GitHub link - blog article incoming). The reason why I chose Tesco as opposed to any other supermarket is because it’s 5 minutes down the road from me.\nIn this article we’ll load, process, transform, and analyse this scraped data to see how the prices of food categories have changed over time. If you want to skip directly to the charts and analysis, head to the ‘Charts and Analysis’ section in the above table of contents.\n\n# hide_input\n\n# Used to enable plotly\nimport plotly.io as pio\npio.renderers.default = 'notebook_connected'\nfrom IPython.display import display, HTML\njs = '<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>'\ndisplay(HTML(js))\n\n\n\n\n\n# hide\nimport boto3\nimport os\nimport io\nimport json\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly_express as px\nimport altair as alt\nfrom functools import reduce\nfrom IPython.display import HTML\n\npd.set_option('display.max_rows', 500)\ns3_client = boto3.client('s3')\n\n\n# hide\n\n# Load data from S3\nraw_df = pd.read_parquet(f's3://tesco-scrape-pipeline-app-tescoscrapes3bucket-1x8yycv16azsa/master_data/scraped_product_data.parquet')\n\n\n# hide\ndtype_map = {\n    'name': str,\n    'price_per_unit': float,\n    'price_per_weight_quant': float,\n    'weight_quant_unit': str,\n    'offer': str,\n    'category_1': str,\n    'category_2': str,\n    'category_3': str,\n    'category_4': str,\n    'clubcard_price_per_unit': float,\n    'clubcard_discount_perc': float,\n    'date': 'date'\n}\n\n# Drop product ID column and rows with NaN values in 'price_per_unit' column\npreproc_df = (\n    raw_df\n    .drop(columns=['id'])\n    .dropna(subset=['price_per_unit'])\n)\n\n# Convert columns to appropriate dtype\nfor col, dtype in dtype_map.items():\n    if dtype == 'date':\n        preproc_df[col] = pd.to_datetime(preproc_df[col], dayfirst=True)\n    else:\n        preproc_df[col] = preproc_df[col].astype(dtype)\n        if dtype == str:\n            preproc_df[col] = preproc_df[col].replace('nan', np.nan)\n\n# Remove irrelevant categories and remove data past 2022-06-13 because it's low quality (many NaN values in columns)\ncat1_mask = preproc_df['category_1'].isin(['baby', 'health-and-beauty', 'home-and-ents', 'summer-bbq', 'easter'])\ndate_mask = preproc_df['date'] <= '2022-06-13'\npreproc_df = preproc_df[(~cat1_mask) & (date_mask)]\n\n\n# hide\n# Still some NaNs in category columns - about 4%\npreproc_df.isna().mean()\n\nname                       0.000000\nprice_per_unit             0.000000\nprice_per_weight_quant     0.000074\nweight_quant_unit          0.000124\noffer                      0.808033\ncategory_1                 0.010347\ncategory_2                 0.010347\ncategory_3                 0.010347\ncategory_4                 0.010347\nclubcard_price_per_unit    0.898618\nclubcard_discount_perc     0.898618\ndate                       0.000000\ndtype: float64\n\n\n\n# hide\n# Shouldn't be any NaNs in the category columns if there are no NaNs in name column\n# Remedy this by creating mappings for product name to product sub-category for all sub-categories and apply to name column\n\nfor sub_cat in ['category_1', 'category_2', 'category_3', 'category_4']:\n    # Create mapping for product name to category sub-type\n    prod_cat_map = {prod_name: cat for prod_name, cat in preproc_df[['name', sub_cat]].dropna().to_numpy()}\n    \n    # Apply mapping\n    preproc_df[sub_cat] = preproc_df['name'].map(prod_cat_map)\n\n\n# hide\n# Much better now\npreproc_df.isna().mean()\n\nname                       0.000000\nprice_per_unit             0.000000\nprice_per_weight_quant     0.000074\nweight_quant_unit          0.000124\noffer                      0.808033\ncategory_1                 0.001082\ncategory_2                 0.001082\ncategory_3                 0.001082\ncategory_4                 0.001082\nclubcard_price_per_unit    0.898618\nclubcard_discount_perc     0.898618\ndate                       0.000000\ndtype: float64"
  },
  {
    "objectID": "posts/2022-09-20-tesco-price-analysis.html#overview-of-price-changes-for-all-categories",
    "href": "posts/2022-09-20-tesco-price-analysis.html#overview-of-price-changes-for-all-categories",
    "title": "solverism-quarto-blog",
    "section": "Overview of Price Changes for All Categories",
    "text": "Overview of Price Changes for All Categories\nLet’s start with the big picture (quite literally), how did prices change when comparing the basket values of categories?\nNote that the index numbers presented in the graph below are accurate when rounding to whole numbers.\nTechnical explanation - The numbers get more inaccurate as you go up category granularities due to the way that the index numbers are aggregated. I’m using the most granular dataset that contains index numbers of quaternary categories, these are then aggregated up to the tertiary category level using the harmonic mean weighted by the basket value of the quaternary categories within the tertiary category. This process repeats for the secondary and then the primary categories, the approximation error increasing going up with each category level.\n\n# hide\n\n# Calculate overall price increase between beginning and end period\nearliest_date_mask = cat_index_dict['category_1']['date'] == '2022-02-28'\nlatest_date_mask = cat_index_dict['category_1']['date'] == '2022-06-13'\n\n(100 * (\n    cat_index_dict['category_1'][latest_date_mask]['total_basket_value'].sum() /\n    cat_index_dict['category_1'][earliest_date_mask]['total_basket_value'].sum()\n    )\n)\n\n101.70219405149523\n\n\nTip: This chart is interactive!  Hover your mouse over the sector to look at the index number of categories (if on mobile, tap and hold the name of the category). Clicking on a sector will focus on that particular category and its subcategories. There are 4 levels of categories but only 3 levels are shown at any one time for better performance.\n\n# hide\n\n# Plotly Express' Sunburst chart aggregates the column given as color argument using weighted arithmetic mean\n# Since we want to use index number column as color argument, weighted arithmentic mean isn't appropriate to use\n# It would be better to use the weighted harmonic mean as index numbers are rates but plotly doesn't given an option to use that as an argument\n# So I'll need to take bits and pieces of their code just to change one line in one function...\nimport math\nimport scipy.stats as scp\nimport plotly.graph_objects as go\nfrom collections import namedtuple, OrderedDict\nfrom plotly.express._special_inputs import IdentityMap, Constant, Range\nfrom plotly.express._core import process_dataframe_pie, process_dataframe_timeline, _is_continuous, \\\n                                configure_animation_controls, configure_axes, _set_trace_grid_reference, init_figure, apply_default_cascade, \\\n                                build_dataframe, make_trace_kwargs, ColorscaleValidator, get_decorated_label, _subplot_type_for_trace_type, \\\n                                infer_config, one_group, get_groups_and_orders, get_label\n\n\ndef sunburst(\n    data_frame=None,\n    names=None,\n    values=None,\n    parents=None,\n    path=None,\n    ids=None,\n    color=None,\n    color_continuous_scale=None,\n    range_color=None,\n    color_continuous_midpoint=None,\n    color_discrete_sequence=None,\n    color_discrete_map=None,\n    hover_name=None,\n    hover_data=None,\n    custom_data=None,\n    labels=None,\n    title=None,\n    template=None,\n    width=None,\n    height=None,\n    branchvalues=None,\n    maxdepth=None,\n) -> go.Figure:\n    \"\"\"\n    A sunburst plot represents hierarchial data as sectors laid out over\n    several levels of concentric rings.\n    \"\"\"\n    if color_discrete_sequence is not None:\n        layout_patch = {\"sunburstcolorway\": color_discrete_sequence}\n    else:\n        layout_patch = {}\n    if path is not None and (ids is not None or parents is not None):\n        raise ValueError(\n            \"Either `path` should be provided, or `ids` and `parents`.\"\n            \"These parameters are mutually exclusive and cannot be passed together.\"\n        )\n    if path is not None and branchvalues is None:\n        branchvalues = \"total\"\n    return make_figure(\n        args=locals(),\n        constructor=go.Sunburst,\n        trace_patch=dict(branchvalues=branchvalues, maxdepth=maxdepth),\n        layout_patch=layout_patch,\n    )\n\n\ndef make_figure(args, constructor, trace_patch=None, layout_patch=None):\n    trace_patch = trace_patch or {}\n    layout_patch = layout_patch or {}\n    apply_default_cascade(args)\n\n    args = build_dataframe(args, constructor)\n    if constructor in [go.Treemap, go.Sunburst, go.Icicle] and args[\"path\"] is not None:\n        args = process_dataframe_hierarchy(args)\n    if constructor in [go.Pie]:\n        args, trace_patch = process_dataframe_pie(args, trace_patch)\n    if constructor == \"timeline\":\n        constructor = go.Bar\n        args = process_dataframe_timeline(args)\n\n    trace_specs, grouped_mappings, sizeref, show_colorbar = infer_config(\n        args, constructor, trace_patch, layout_patch\n    )\n    grouper = [x.grouper or one_group for x in grouped_mappings] or [one_group]\n    groups, orders = get_groups_and_orders(args, grouper)\n\n    col_labels = []\n    row_labels = []\n    nrows = ncols = 1\n    for m in grouped_mappings:\n        if m.grouper not in orders:\n            m.val_map[\"\"] = m.sequence[0]\n        else:\n            sorted_values = orders[m.grouper]\n            if m.facet == \"col\":\n                prefix = get_label(args, args[\"facet_col\"]) + \"=\"\n                col_labels = [prefix + str(s) for s in sorted_values]\n                ncols = len(col_labels)\n            if m.facet == \"row\":\n                prefix = get_label(args, args[\"facet_row\"]) + \"=\"\n                row_labels = [prefix + str(s) for s in sorted_values]\n                nrows = len(row_labels)\n            for val in sorted_values:\n                if val not in m.val_map:  # always False if it's an IdentityMap\n                    m.val_map[val] = m.sequence[len(m.val_map) % len(m.sequence)]\n\n    subplot_type = _subplot_type_for_trace_type(constructor().type)\n\n    trace_names_by_frame = {}\n    frames = OrderedDict()\n    trendline_rows = []\n    trace_name_labels = None\n    facet_col_wrap = args.get(\"facet_col_wrap\", 0)\n    for group_name, group in groups.items():\n        mapping_labels = OrderedDict()\n        trace_name_labels = OrderedDict()\n        frame_name = \"\"\n        for col, val, m in zip(grouper, group_name, grouped_mappings):\n            if col != one_group:\n                key = get_label(args, col)\n                if not isinstance(m.val_map, IdentityMap):\n                    mapping_labels[key] = str(val)\n                    if m.show_in_trace_name:\n                        trace_name_labels[key] = str(val)\n                if m.variable == \"animation_frame\":\n                    frame_name = val\n        trace_name = \", \".join(trace_name_labels.values())\n        if frame_name not in trace_names_by_frame:\n            trace_names_by_frame[frame_name] = set()\n        trace_names = trace_names_by_frame[frame_name]\n\n        for trace_spec in trace_specs:\n            # Create the trace\n            trace = trace_spec.constructor(name=trace_name)\n            if trace_spec.constructor not in [\n                go.Parcats,\n                go.Parcoords,\n                go.Choropleth,\n                go.Choroplethmapbox,\n                go.Densitymapbox,\n                go.Histogram2d,\n                go.Sunburst,\n                go.Treemap,\n                go.Icicle,\n            ]:\n                trace.update(\n                    legendgroup=trace_name,\n                    showlegend=(trace_name != \"\" and trace_name not in trace_names),\n                )\n            if trace_spec.constructor in [go.Bar, go.Violin, go.Box, go.Histogram]:\n                trace.update(alignmentgroup=True, offsetgroup=trace_name)\n            trace_names.add(trace_name)\n\n            # Init subplot row/col\n            trace._subplot_row = 1\n            trace._subplot_col = 1\n\n            for i, m in enumerate(grouped_mappings):\n                val = group_name[i]\n                try:\n                    m.updater(trace, m.val_map[val])  # covers most cases\n                except ValueError:\n                    # this catches some odd cases like marginals\n                    if (\n                        trace_spec != trace_specs[0]\n                        and (\n                            trace_spec.constructor in [go.Violin, go.Box]\n                            and m.variable in [\"symbol\", \"pattern\", \"dash\"]\n                        )\n                        or (\n                            trace_spec.constructor in [go.Histogram]\n                            and m.variable in [\"symbol\", \"dash\"]\n                        )\n                    ):\n                        pass\n                    elif (\n                        trace_spec != trace_specs[0]\n                        and trace_spec.constructor in [go.Histogram]\n                        and m.variable == \"color\"\n                    ):\n                        trace.update(marker=dict(color=m.val_map[val]))\n                    elif (\n                        trace_spec.constructor in [go.Choropleth, go.Choroplethmapbox]\n                        and m.variable == \"color\"\n                    ):\n                        trace.update(\n                            z=[1] * len(group),\n                            colorscale=[m.val_map[val]] * 2,\n                            showscale=False,\n                            showlegend=True,\n                        )\n                    else:\n                        raise\n\n                # Find row for trace, handling facet_row and marginal_x\n                if m.facet == \"row\":\n                    row = m.val_map[val]\n                else:\n                    if (\n                        args.get(\"marginal_x\") is not None  # there is a marginal\n                        and trace_spec.marginal != \"x\"  # and we're not it\n                    ):\n                        row = 2\n                    else:\n                        row = 1\n\n                # Find col for trace, handling facet_col and marginal_y\n                if m.facet == \"col\":\n                    col = m.val_map[val]\n                    if facet_col_wrap:  # assumes no facet_row, no marginals\n                        row = 1 + ((col - 1) // facet_col_wrap)\n                        col = 1 + ((col - 1) % facet_col_wrap)\n                else:\n                    if trace_spec.marginal == \"y\":\n                        col = 2\n                    else:\n                        col = 1\n\n                if row > 1:\n                    trace._subplot_row = row\n\n                if col > 1:\n                    trace._subplot_col = col\n            if (\n                trace_specs[0].constructor == go.Histogram2dContour\n                and trace_spec.constructor == go.Box\n                and trace.line.color\n            ):\n                trace.update(marker=dict(color=trace.line.color))\n\n            if \"ecdfmode\" in args:\n                base = args[\"x\"] if args[\"orientation\"] == \"v\" else args[\"y\"]\n                var = args[\"x\"] if args[\"orientation\"] == \"h\" else args[\"y\"]\n                ascending = args.get(\"ecdfmode\", \"standard\") != \"reversed\"\n                group = group.sort_values(by=base, ascending=ascending)\n                group_sum = group[var].sum()  # compute here before next line mutates\n                group[var] = group[var].cumsum()\n                if not ascending:\n                    group = group.sort_values(by=base, ascending=True)\n\n                if args.get(\"ecdfmode\", \"standard\") == \"complementary\":\n                    group[var] = group_sum - group[var]\n\n                if args[\"ecdfnorm\"] == \"probability\":\n                    group[var] = group[var] / group_sum\n                elif args[\"ecdfnorm\"] == \"percent\":\n                    group[var] = 100.0 * group[var] / group_sum\n\n            patch, fit_results = make_trace_kwargs(\n                args, trace_spec, group, mapping_labels.copy(), sizeref\n            )\n            trace.update(patch)\n            if fit_results is not None:\n                trendline_rows.append(mapping_labels.copy())\n                trendline_rows[-1][\"px_fit_results\"] = fit_results\n            if frame_name not in frames:\n                frames[frame_name] = dict(data=[], name=frame_name)\n            frames[frame_name][\"data\"].append(trace)\n    frame_list = [f for f in frames.values()]\n    if len(frame_list) > 1:\n        frame_list = sorted(\n            frame_list, key=lambda f: orders[args[\"animation_frame\"]].index(f[\"name\"])\n        )\n\n    if show_colorbar:\n        colorvar = \"z\" if constructor in [go.Histogram2d, go.Densitymapbox] else \"color\"\n        range_color = args[\"range_color\"] or [None, None]\n\n        colorscale_validator = ColorscaleValidator(\"colorscale\", \"make_figure\")\n        layout_patch[\"coloraxis1\"] = dict(\n            colorscale=colorscale_validator.validate_coerce(\n                args[\"color_continuous_scale\"]\n            ),\n            cmid=args[\"color_continuous_midpoint\"],\n            cmin=range_color[0],\n            cmax=range_color[1],\n            colorbar=dict(\n                title_text=get_decorated_label(args, args[colorvar], colorvar)\n            ),\n        )\n    for v in [\"height\", \"width\"]:\n        if args[v]:\n            layout_patch[v] = args[v]\n    layout_patch[\"legend\"] = dict(tracegroupgap=0)\n    if trace_name_labels:\n        layout_patch[\"legend\"][\"title_text\"] = \", \".join(trace_name_labels)\n    if args[\"title\"]:\n        layout_patch[\"title_text\"] = args[\"title\"]\n    elif args[\"template\"].layout.margin.t is None:\n        layout_patch[\"margin\"] = {\"t\": 60}\n    if (\n        \"size\" in args\n        and args[\"size\"]\n        and args[\"template\"].layout.legend.itemsizing is None\n    ):\n        layout_patch[\"legend\"][\"itemsizing\"] = \"constant\"\n\n    if facet_col_wrap:\n        nrows = math.ceil(ncols / facet_col_wrap)\n        ncols = min(ncols, facet_col_wrap)\n\n    if args.get(\"marginal_x\") is not None:\n        nrows += 1\n\n    if args.get(\"marginal_y\") is not None:\n        ncols += 1\n\n    fig = init_figure(\n        args, subplot_type, frame_list, nrows, ncols, col_labels, row_labels\n    )\n\n    # Position traces in subplots\n    for frame in frame_list:\n        for trace in frame[\"data\"]:\n            if isinstance(trace, go.Splom):\n                # Special case that is not compatible with make_subplots\n                continue\n\n            _set_trace_grid_reference(\n                trace,\n                fig.layout,\n                fig._grid_ref,\n                nrows - trace._subplot_row + 1,\n                trace._subplot_col,\n            )\n\n    # Add traces, layout and frames to figure\n    fig.add_traces(frame_list[0][\"data\"] if len(frame_list) > 0 else [])\n    fig.update_layout(layout_patch)\n    if \"template\" in args and args[\"template\"] is not None:\n        fig.update_layout(template=args[\"template\"], overwrite=True)\n    for f in frame_list:\n        f[\"name\"] = str(f[\"name\"])\n    fig.frames = frame_list if len(frames) > 1 else []\n\n    if args.get(\"trendline\") and args.get(\"trendline_scope\", \"trace\") == \"overall\":\n        trendline_spec = make_trendline_spec(args, constructor)\n        trendline_trace = trendline_spec.constructor(\n            name=\"Overall Trendline\", legendgroup=\"Overall Trendline\", showlegend=False\n        )\n        if \"line\" not in trendline_spec.trace_patch:  # no color override\n            for m in grouped_mappings:\n                if m.variable == \"color\":\n                    next_color = m.sequence[len(m.val_map) % len(m.sequence)]\n                    trendline_spec.trace_patch[\"line\"] = dict(color=next_color)\n        patch, fit_results = make_trace_kwargs(\n            args, trendline_spec, args[\"data_frame\"], {}, sizeref\n        )\n        trendline_trace.update(patch)\n        fig.add_trace(\n            trendline_trace, row=\"all\", col=\"all\", exclude_empty_subplots=True\n        )\n        fig.update_traces(selector=-1, showlegend=True)\n        if fit_results is not None:\n            trendline_rows.append(dict(px_fit_results=fit_results))\n\n    fig._px_trendlines = pd.DataFrame(trendline_rows)\n\n    configure_axes(args, constructor, fig, orders)\n    configure_animation_controls(args, constructor, fig)\n    return fig\n\n\ndef _check_dataframe_all_leaves(df):\n    df_sorted = df.sort_values(by=list(df.columns))\n    null_mask = df_sorted.isnull()\n    df_sorted = df_sorted.astype(str)\n    null_indices = np.nonzero(null_mask.any(axis=1).values)[0]\n    for null_row_index in null_indices:\n        row = null_mask.iloc[null_row_index]\n        i = np.nonzero(row.values)[0][0]\n        if not row[i:].all():\n            raise ValueError(\n                \"None entries cannot have not-None children\",\n                df_sorted.iloc[null_row_index],\n            )\n    df_sorted[null_mask] = \"\"\n    row_strings = list(df_sorted.apply(lambda x: \"\".join(x), axis=1))\n    for i, row in enumerate(row_strings[:-1]):\n        if row_strings[i + 1] in row and (i + 1) in null_indices:\n            raise ValueError(\n                \"Non-leaves rows are not permitted in the dataframe \\n\",\n                df_sorted.iloc[i + 1],\n                \"is not a leaf.\",\n            )\n\n\n# The one line of code that needs to be changed is in the inner function named 'aggfunc_continuous'\ndef process_dataframe_hierarchy(args):\n    \"\"\"\n    Build dataframe for sunburst, treemap, or icicle when the path argument is provided.\n    \"\"\"\n    df = args[\"data_frame\"]\n    path = args[\"path\"][::-1]\n    _check_dataframe_all_leaves(df[path[::-1]])\n    discrete_color = False\n\n    new_path = []\n    for col_name in path:\n        new_col_name = col_name + \"_path_copy\"\n        new_path.append(new_col_name)\n        df[new_col_name] = df[col_name]\n    path = new_path\n    # ------------ Define aggregation functions --------------------------------\n\n    def aggfunc_discrete(x):\n        uniques = x.unique()\n        if len(uniques) == 1:\n            return uniques[0]\n        else:\n            return \"(?)\"\n\n    agg_f = {}\n    aggfunc_color = None\n    if args[\"values\"]:\n        try:\n            df[args[\"values\"]] = pd.to_numeric(df[args[\"values\"]])\n        except ValueError:\n            raise ValueError(\n                \"Column `%s` of `df` could not be converted to a numerical data type.\"\n                % args[\"values\"]\n            )\n\n        if args[\"color\"]:\n            if args[\"color\"] == args[\"values\"]:\n                new_value_col_name = args[\"values\"] + \"_sum\"\n                df[new_value_col_name] = df[args[\"values\"]]\n                args[\"values\"] = new_value_col_name\n        count_colname = args[\"values\"]\n    else:\n        # we need a count column for the first groupby and the weighted mean of color\n        # trick to be sure the col name is unused: take the sum of existing names\n        count_colname = (\n            \"count\"\n            if \"count\" not in df.columns\n            else \"\".join([str(el) for el in list(df.columns)])\n        )\n        # we can modify df because it's a copy of the px argument\n        df[count_colname] = 1\n        args[\"values\"] = count_colname\n    agg_f[count_colname] = \"sum\"\n\n    if args[\"color\"]:\n        if not _is_continuous(df, args[\"color\"]):\n            aggfunc_color = aggfunc_discrete\n            discrete_color = True\n        else:\n\n            def aggfunc_continuous(x):\n                return scp.hmean(x, weights=df.loc[x.index, count_colname])\n\n            aggfunc_color = aggfunc_continuous\n        agg_f[args[\"color\"]] = aggfunc_color\n\n    #  Other columns (for color, hover_data, custom_data etc.)\n    cols = list(set(df.columns).difference(path))\n    for col in cols:  # for hover_data, custom_data etc.\n        if col not in agg_f:\n            agg_f[col] = aggfunc_discrete\n    # Avoid collisions with reserved names - columns in the path have been copied already\n    cols = list(set(cols) - set([\"labels\", \"parent\", \"id\"]))\n    # ----------------------------------------------------------------------------\n    df_all_trees = pd.DataFrame(columns=[\"labels\", \"parent\", \"id\"] + cols)\n    #  Set column type here (useful for continuous vs discrete colorscale)\n    for col in cols:\n        df_all_trees[col] = df_all_trees[col].astype(df[col].dtype)\n    for i, level in enumerate(path):\n        df_tree = pd.DataFrame(columns=df_all_trees.columns)\n        dfg = df.groupby(path[i:]).agg(agg_f)\n        dfg = dfg.reset_index()\n        # Path label massaging\n        df_tree[\"labels\"] = dfg[level].copy().astype(str)\n        df_tree[\"parent\"] = \"\"\n        df_tree[\"id\"] = dfg[level].copy().astype(str)\n        if i < len(path) - 1:\n            j = i + 1\n            while j < len(path):\n                df_tree[\"parent\"] = (\n                    dfg[path[j]].copy().astype(str) + \"/\" + df_tree[\"parent\"]\n                )\n                df_tree[\"id\"] = dfg[path[j]].copy().astype(str) + \"/\" + df_tree[\"id\"]\n                j += 1\n\n        df_tree[\"parent\"] = df_tree[\"parent\"].str.rstrip(\"/\")\n        if cols:\n            df_tree[cols] = dfg[cols]\n        df_all_trees = pd.concat([df_all_trees, df_tree], ignore_index=True)\n\n    # we want to make sure than (?) is the first color of the sequence\n    if args[\"color\"] and discrete_color:\n        sort_col_name = \"sort_color_if_discrete_color\"\n        while sort_col_name in df_all_trees.columns:\n            sort_col_name += \"0\"\n        df_all_trees[sort_col_name] = df[args[\"color\"]].astype(str)\n        df_all_trees = df_all_trees.sort_values(by=sort_col_name)\n\n    # Now modify arguments\n    args[\"data_frame\"] = df_all_trees\n    args[\"path\"] = None\n    args[\"ids\"] = \"id\"\n    args[\"names\"] = \"labels\"\n    args[\"parents\"] = \"parent\"\n    if args[\"color\"]:\n        if not args[\"hover_data\"]:\n            args[\"hover_data\"] = [args[\"color\"]]\n        elif isinstance(args[\"hover_data\"], dict):\n            if not args[\"hover_data\"].get(args[\"color\"]):\n                args[\"hover_data\"][args[\"color\"]] = (True, None)\n        else:\n            args[\"hover_data\"].append(args[\"color\"])\n    return args\n\n\n# hide_input\n\ntmp_df = cat_index_dict['category_4'].reset_index(drop=True).copy()\nlatest_date_mask = tmp_df['date'] == '2022-06-13'\n\nfig = sunburst(\n    tmp_df[latest_date_mask].drop_duplicates(subset=['category_4']),\n    path=['category_1', 'category_2', 'category_3', 'category_4'],\n    values='total_basket_value',\n    color='index',\n    branchvalues='total',\n    range_color=[90,110],\n    color_continuous_scale='balance',\n    color_continuous_midpoint=100,\n    width=1100,\n    height=950,\n    maxdepth=3\n)\n\nfig.update_coloraxes(colorbar=dict(len=0.75))\nfig.update_layout(margin=dict(l=0, r=0, t=20, b=20))\nfig.show()\n\n\n                                                \n\n\nStraight away we can see that fresh food and frozen food have increased by ~3% and ~4% respectively. The major contributing subcategories for fresh food are cheese (~5% increase); fresh meat and poultry (~5% increase); ready meals (~4% increase); and yogurts (~4% increase). For frozen food, the major contributing subcategories are frozen fish and seafood (~9% increase); frozen chips, onion rings, potatoes, and rice (~12% increase); and frozen meat and poultry (~5% increase).\nYikes, no wonder why my shopping bill has been going up. Fresh chicken breast and thighs have gone up by over 10%!\nOverall, prices have by 1.7% across all categories and products in the processed dataset.\nWe can also see there are a few secondary categories that have gone down, most notably is the cooking sauces, meal kits, and sides subcategory within the food cupboard category which has gone down by ~2%. This does raise another question though, how many categories in each level experienced an increase, decrease, or no change in price?\n\n# hide\ndata_list = []\ncat_type_map = {\n    'category_2': 'Secondary Categories',\n    'category_3': 'Tertiary Categories',\n    'category_4': 'Quaternary Categories'\n}\nfor cat_type in ['category_2', 'category_3', 'category_4']:\n    date_mask = cat_index_dict[cat_type]['date'] == '2022-06-13'\n    \n    for cat_1 in cat_index_dict[cat_type]['category_1'].unique():\n        cat_1_mask = cat_index_dict[cat_type]['category_1'] == cat_1\n        mapped_cat_type = cat_type_map[cat_type]\n        # cat_title = ' '.join(cat_1.split('-')).title()\n        \n        data_list.append({\n            'Category Type': mapped_cat_type,\n            'Primary Category': cat_1,\n            'Number': (cat_index_dict[cat_type][date_mask & cat_1_mask]['index'] > 100).sum(),\n            'Change': 'Increase'\n        })\n        \n        data_list.append({\n            'Category Type': mapped_cat_type,\n            'Primary Category': cat_1,\n            'Number': (cat_index_dict[cat_type][date_mask & cat_1_mask]['index'] < 100).sum(),\n            'Change': 'Decrease'\n        })\n        \n        data_list.append({\n            'Category Type': mapped_cat_type,\n            'Primary Category': cat_1,\n            'Number': (cat_index_dict[cat_type][date_mask & cat_1_mask]['index'] == 100).sum(),\n            'Change': 'No Change'\n        })\n\nchanges_df = pd.DataFrame(data_list)\nchanges_df = changes_df.merge(\n    right = (changes_df\n    .groupby(by=['Category Type', 'Primary Category'])\n    ['Number']\n    .sum()\n    .reset_index()\n    .rename(columns={'Number': 'Sum'})),\n    on=['Category Type', 'Primary Category'],\n    how='left'\n)\nchanges_df['Percentage'] = (changes_df['Number'] / changes_df['Sum'])\n\n\n# hide_input\norder = ['Decrease', 'No Change', 'Increase'][::-1]\nrange_ = ['#4c78a8', '#cccccc', '#e45756'][::-1]\n\nalt.Chart(changes_df).transform_calculate(\n    order=f\"-indexof({order}, datum.Change)\"\n).mark_bar().encode(\n    x=alt.X('Percentage', axis=alt.Axis(title=\"Percent\", format=\"%\")),\n    y='Primary Category',\n    color=alt.Color('Change', scale=alt.Scale(domain=order, range=range_)),\n    column=alt.Column('Category Type', sort=['Secondary Categories', 'Tertiary Categories', 'Quaternary Categories']),\n    order=\"order:Q\",\n    tooltip=[\n        alt.Tooltip('Number', title=\"Number of Subcategories\"),\n        alt.Tooltip('Sum', title=\"Total Subcategories\"),\n        alt.Tooltip('Percentage', title=\"Percentage\", format='.1%'),\n    ],\n).properties(\n    width=270,\n    height=250,\n    title='Percentage of subcategories that have increased, decreased, or stayed the same in basket value',\n).configure_title(\n    fontSize=17,\n    dy=-25,\n).configure_header(\n    titleFontSize=15,\n    labelFontSize=14\n).configure_axis(\n    labelFontSize=14,\n    titleFontSize=15\n).configure_legend(\ntitleFontSize=14,\nlabelFontSize=13\n) \n\n\n\n\n\n\nIt’s very clear from the above that the bakery and frozen food primary categories had all secondary, tertiary, and quaternary subcategories either increase in price or stay the same! We’ll have to note that they’re the two smallest primary categories by both total basket value and number of subcategories, but there are ongoing macroeconomic events that are affecting both the supply chain and cost of businesses.\nAs of writing, the 2022 Russian invasion of Ukraine is affecting the two largest global suppliers of wheat. Russia produces 11% of the world’s wheat and accounts for 19% of global wheat exports. On the other hand, Ukraine produces 3% of the world’s wheat and accounts for 9% of global wheat exports. Both of these together account for more than a quarter of the world’s wheat export market {% fn 1 %}. You can guess what ingredient bakery goods use that’s derived from wheat.\nEnergy prices have also been rising throughout 2022 and are forecasted to reach unprecedented levels during the first two quarters of 2023. The electricity price (kWh) cap rose from 20.8p in Q1 2022 to 28.3p in Q2 2022 {% fn 2 %}, an increase of 36%. This will affect the production costs of all goods, more so if they need to be kept cold or frozen.\nGenerally speaking, it does seem that the vast majority of subcategories have experienced an increase in price, no matter what level of category granularity is being looked at. The drinks and food cupboard primary categories are the least affected as they’re the only two that contain secondary categories that have decreased in price; that being said they only account for 11.1% and 18.8% of the total number of their respective total secondary categories.\n{{ ‘Source: https://asmith.ucdavis.edu/news/russia-ukraine’ | fndetail: 1 }} {{ ‘Source: https://www.icaew.com/insights/viewpoints-on-the-news/2022/sept-2022/chart-of-the-week-energy-price-cap-update’ | fndetail: 2 }}"
  },
  {
    "objectID": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-primary-food-categories",
    "href": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-primary-food-categories",
    "title": "solverism-quarto-blog",
    "section": "Price Changes for Primary Food Categories",
    "text": "Price Changes for Primary Food Categories\nLet’s now take a look at how the index of primary categories changed over time as opposed to a snapshot in time.\n\n# hide_input\n\nselection = alt.selection_multi(fields=['category_1'], bind='legend')\n\nbase = alt.Chart(cat_index_dict['category_1'].reset_index()).mark_line().encode(\n    y=alt.Y(shorthand='index', scale=alt.Scale(zero=False), axis=alt.Axis(title='Index')),\n    x=alt.X(shorthand='date', axis=alt.Axis(title='Week Commencing Monday')),\n    color=alt.Color('category_1', legend=alt.Legend(title=\"Food Category\")),\n    strokeDash='category_1',\n    opacity=alt.condition(selection, alt.value(1), alt.value(0.2))\n).add_selection(\n    selection\n).properties(\n    title='Index of Main Tesco Food Categories',\n    width=900,\n    height=500\n)\n\nhover = alt.selection_single(\n    fields=[\"date\"],\n    nearest=True,\n    on=\"mouseover\",\n    empty=\"none\",\n    clear=\"mouseout\",\n)\n\ntooltips = alt.Chart(cat_index_dict['category_1'].reset_index()).transform_pivot(\n    \"category_1\", \"index\", groupby=[\"date\"]\n).mark_rule(strokeWidth=2, color=\"grey\").encode(\n    x='date:T',\n    opacity=alt.condition(hover, alt.value(0.75), alt.value(0)),\n    tooltip=[\"date:T\"]+[alt.Tooltip(f\"{cat_1}:Q\", format='.2f') for cat_1 in cat_index_dict['category_1']['category_1'].unique()],\n).add_selection(hover)\n\n\n(base + tooltips).configure_title(\n    fontSize=17\n).configure_axis(\n    labelFontSize=13,\n    titleFontSize=15\n).configure_legend(\ntitleFontSize=14,\nlabelFontSize=13\n) \n\n\n\n\n\n\nThere are a few things I’m seeing from this graph. First is that bakery, drinks, and food cupboard items seem to be plateauing where as fresh and frozen items don’t seem to be slowing down. Second, the fresh and frozen items have the highest rate of increase amongst all primary categories. Third, the food cupboard and drinks categories seem to increase at the same rate were it not for the initial hike on 6th March. Finally, the bakery category is the only one that looks to practically stay the same for the first five weeks before rapidly increasing at the same rate as the fresh and frozen food categories and then plateauing.\nThe big question that comes to mind is what’s driving the price of fresh food items to go up? If we extrapolate out the trend for an entire year, we’re looking at an approximate increase of 12.5% for both categories! To answer this question we’ll have to dive into the secondary categories."
  },
  {
    "objectID": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-fresh-food-subcategories",
    "href": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-fresh-food-subcategories",
    "title": "solverism-quarto-blog",
    "section": "Price Changes for Fresh Food Subcategories",
    "text": "Price Changes for Fresh Food Subcategories\n\n# hide_input\n\nprimary_cat = 'fresh-food'\nmask = cat_index_dict['category_2']['category_1'] == primary_cat\n\nselection = alt.selection_multi(fields=['category_2'], bind='legend')\n\nbase = alt.Chart(cat_index_dict['category_2'][mask].reset_index()).mark_line().encode(\n    y=alt.Y(shorthand='index', scale=alt.Scale(zero=False), axis=alt.Axis(title='Index')),\n    x=alt.X(shorthand='date', axis=alt.Axis(title='Week Commencing Monday')),\n    color=alt.Color('category_2', legend=alt.Legend(title=f\"{' '.join(primary_cat.split('-')).title()} Subcategory\")),\n    strokeDash='category_2',\n    opacity=alt.condition(selection, alt.value(1), alt.value(0.2))\n).add_selection(\n    selection\n).properties(\n    title=f\"Index of Tesco Food Subcategories for {' '.join(primary_cat.split('-')).title()} Category\",\n    width=825,\n    height=500\n)\n\nhover = alt.selection_single(\n    fields=[\"date\"],\n    nearest=True,\n    on=\"mouseover\",\n    empty=\"none\",\n    clear=\"mouseout\",\n)\n\ntooltips = alt.Chart(cat_index_dict['category_2'][mask].reset_index()).transform_pivot(\n    \"category_2\", \"index\", groupby=[\"date\"]\n).mark_rule(strokeWidth=2, color=\"grey\").encode(\n    x='date:T',\n    opacity=alt.condition(hover, alt.value(0.75), alt.value(0)),\n    tooltip=[\"date:T\"]+[alt.Tooltip(f\"{cat_1}:Q\", format='.2f') for cat_1 in cat_index_dict['category_2'][mask]['category_2'].unique()],\n).add_selection(hover)\n\n\n(base + tooltips).configure_title(\n    fontSize=17\n).configure_axis(\n    labelFontSize=13,\n    titleFontSize=15\n).configure_legend(\ntitleFontSize=14,\nlabelFontSize=13\n) \n\n\n\n\n\n\n\nWow there’s a lot going on in that graph, but can definitely be seen that some secondary categories much more than others. Let’s take a look at the index values at the end of the graph to quickly look at which secondary categories increased the most.\n\n# hide_input\ntmp_df = cat_index_dict['category_2'][mask]\nlatest_date_mask = tmp_df['date'] == '2022-06-13'\n\n(\n    tmp_df[latest_date_mask]\n    .sort_values(by='index', ascending=False)\n    .reset_index(drop=True)\n    .rename(columns={\n        'date': 'Week Commencing Monday',\n        'category_1': 'Primary Category',\n        'category_2': 'Secondary Category',\n        'total_basket_value': 'Total Basket Value',\n        'index': 'Index'\n    })\n)\n\n\n\n\n\n  \n    \n      \n      Week Commencing Monday\n      Primary Category\n      Secondary Category\n      Total Basket Value\n      Index\n    \n  \n  \n    \n      0\n      2022-06-13\n      fresh-food\n      cheese\n      543.920\n      104.728897\n    \n    \n      1\n      2022-06-13\n      fresh-food\n      fresh-meat-and-poultry\n      1311.260\n      104.720680\n    \n    \n      2\n      2022-06-13\n      fresh-food\n      yoghurts\n      389.490\n      104.130574\n    \n    \n      3\n      2022-06-13\n      fresh-food\n      cooked-meats-antipasti-and-dips\n      537.090\n      103.952233\n    \n    \n      4\n      2022-06-13\n      fresh-food\n      chilled-fish-and-seafood\n      270.530\n      103.560081\n    \n    \n      5\n      2022-06-13\n      fresh-food\n      milk-butter-and-eggs\n      324.880\n      103.136508\n    \n    \n      6\n      2022-06-13\n      fresh-food\n      ready-meals\n      653.295\n      102.981651\n    \n    \n      7\n      2022-06-13\n      fresh-food\n      pies-pasties-quiches-and-snacking\n      322.310\n      102.828247\n    \n    \n      8\n      2022-06-13\n      fresh-food\n      fresh-salad-coleslaw-and-sandwich-fillers\n      152.960\n      102.348612\n    \n    \n      9\n      2022-06-13\n      fresh-food\n      chilled-vegetarian-and-vegan\n      290.600\n      102.287927\n    \n    \n      10\n      2022-06-13\n      fresh-food\n      chilled-soup-sandwiches-and-salad-pots\n      226.000\n      101.870633\n    \n    \n      11\n      2022-06-13\n      fresh-food\n      dairy-free-and-dairy-alternatives\n      328.150\n      101.846679\n    \n    \n      12\n      2022-06-13\n      fresh-food\n      chilled-desserts\n      275.900\n      101.804361\n    \n    \n      13\n      2022-06-13\n      fresh-food\n      fresh-vegetables\n      164.090\n      101.742312\n    \n    \n      14\n      2022-06-13\n      fresh-food\n      juice-and-smoothies\n      44.010\n      100.617284\n    \n    \n      15\n      2022-06-13\n      fresh-food\n      fresh-pizza-pasta-and-garlic-bread\n      292.380\n      100.298446\n    \n    \n      16\n      2022-06-13\n      fresh-food\n      counters\n      100.250\n      100.099850\n    \n    \n      17\n      2022-06-13\n      fresh-food\n      fresh-fruit\n      239.010\n      100.098419\n    \n  \n\n\n\n\nLooking at the top 6 rows, it’s primarily dairy and fresh meat and poultry that’s driving up the index of fresh food items. Both of these being products produced from animals.\nAccording to the Specialty Food Magazine, the price increase of dairy products can be largely attributed to the spiralling price of feed, fuel, and fertiliser{% fn 3 %}. All of these three production costs have been subject to large price hikes. For feed and fertiliser, it can be attributed to the Russian invasion on Ukraine, higher energy costs, and increased global demand{% fn 4 %}. For fuel, the primary driver is an increase in the refining cost of crude oil{% fn 5 %}.\nIn Specialty Food Magazine’s article they have a quote from the vice-chair of the National Union of Farmers that it takes him two and a half years to get a cow from being born to be actually producing milk which incurs a lot of cost over the time period. In order to maintain their profit margins, they must raise their prices.\n{{ ‘Source: https://www.specialityfoodmagazine.com/news/dairy-crisis-threatens-spiralling-costs-of-cheese-and-milk-for-indies’ | fndetail: 3 }} {{ ‘Source: https://lordslibrary.parliament.uk/rising-cost-of-agricultural-fertiliser-and-feed-causes-impacts-and-government-policy/’ | fndetail: 4 }} {{ ‘Source: https://www.allstarcard.co.uk/news-insights/business/why-is-fuel-expensive/’ | fndetail: 5 }}"
  },
  {
    "objectID": "posts/2022-09-20-tesco-price-analysis.html#correlation-heatmap-of-all-secondary-categories",
    "href": "posts/2022-09-20-tesco-price-analysis.html#correlation-heatmap-of-all-secondary-categories",
    "title": "solverism-quarto-blog",
    "section": "Correlation Heatmap of All Secondary Categories",
    "text": "Correlation Heatmap of All Secondary Categories\nNote that the below graph is using Pearson’s Correlation coefficient. When the index of two subcategories move in tandem (i.e. they’ve got a positive correlation) the rectange will show as red, the stronger the correlation the more red the rectangle will be. Similar logic applies for when two subcategories move in opposite directions, except with blue. Interesting observation that the adult soft drink and mixers subcategory (first row/column) isn’t showing much of a correlation with anything else.\n\n# hide_input\npx.imshow(\n    cat_index_dict['category_2'].pivot_table(index='date', columns=['category_2'], values='index').corr(),\n    labels=dict(x=\"Secondary Category\", y=\"Secondary Category\", color=\"Correlation\"),\n    color_continuous_scale='balance',\n    color_continuous_midpoint=0,\n    aspect=\"auto\",\n    height=1000,\n    width=1100\n)"
  },
  {
    "objectID": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-fresh-meat-and-poultry-subcategories",
    "href": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-fresh-meat-and-poultry-subcategories",
    "title": "solverism-quarto-blog",
    "section": "Price Changes for Fresh Meat and Poultry Subcategories",
    "text": "Price Changes for Fresh Meat and Poultry Subcategories\n\n# hide_input\n\nprimary_cat = 'fresh-food'\nsubcat_1 = 'fresh-meat-and-poultry'\nmask = (cat_index_dict['category_3']['category_1'] == primary_cat) & (cat_index_dict['category_3']['category_2'] == subcat_1)\n\nselection = alt.selection_multi(fields=['category_3'], bind='legend')\n\nbase = alt.Chart(cat_index_dict['category_3'][mask].reset_index()).mark_line().encode(\n    y=alt.Y(shorthand='index', scale=alt.Scale(zero=False), axis=alt.Axis(title='Index')),\n    x=alt.X(shorthand='date', axis=alt.Axis(title='Week Commencing Monday')),\n    color=alt.Color('category_3', legend=alt.Legend(title=f\"{' '.join(subcat_1.split('-')).title()} Subcategory\")),\n    strokeDash='category_3',\n    opacity=alt.condition(selection, alt.value(1), alt.value(0.2))\n).add_selection(\n    selection\n).properties(\n    title=f\"Index of Tesco Food Subcategories for {' '.join(subcat_1.split('-')).title()} Subcategory\",\n    width=800,\n    height=500\n)\n\nhover = alt.selection_single(\n    fields=[\"date\"],\n    nearest=True,\n    on=\"mouseover\",\n    empty=\"none\",\n    clear=\"mouseout\",\n)\n\ntooltips = alt.Chart(cat_index_dict['category_3'][mask].reset_index()).transform_pivot(\n    \"category_3\", \"index\", groupby=[\"date\"]\n).mark_rule(strokeWidth=2, color=\"grey\").encode(\n    x='date:T',\n    opacity=alt.condition(hover, alt.value(0.75), alt.value(0)),\n    tooltip=[\"date:T\"]+[alt.Tooltip(f\"{cat_1}:Q\", format='.2f') for cat_1 in cat_index_dict['category_3'][mask]['category_3'].unique()],\n).add_selection(hover)\n\n\n(base + tooltips).configure_title(\n    fontSize=17\n).configure_axis(\n    labelFontSize=13,\n    titleFontSize=15\n).configure_legend(\ntitleFontSize=14,\nlabelFontSize=13\n)"
  },
  {
    "objectID": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-cheese-subcategories",
    "href": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-cheese-subcategories",
    "title": "solverism-quarto-blog",
    "section": "Price Changes for Cheese Subcategories",
    "text": "Price Changes for Cheese Subcategories\n\n# hide_input\n\nprimary_cat = 'fresh-food'\nsubcat_1 = 'cheese'\nmask = (cat_index_dict['category_3']['category_1'] == primary_cat) & (cat_index_dict['category_3']['category_2'] == subcat_1)\n\nselection = alt.selection_multi(fields=['category_3'], bind='legend')\n\nbase = alt.Chart(cat_index_dict['category_3'][mask].reset_index()).mark_line().encode(\n    y=alt.Y(shorthand='index', scale=alt.Scale(zero=False), axis=alt.Axis(title='Index')),\n    x=alt.X(shorthand='date', axis=alt.Axis(title='Week Commencing Monday')),\n    color=alt.Color('category_3', legend=alt.Legend(title=f\"{' '.join(subcat_1.split('-')).title()} Subcategory\")),\n    strokeDash='category_3',\n    opacity=alt.condition(selection, alt.value(1), alt.value(0.2))\n).add_selection(\n    selection\n).properties(\n    title=f\"Index of Tesco Food Subcategories for {' '.join(subcat_1.split('-')).title()} Subcategory\",\n    width=800,\n    height=500\n)\n\nhover = alt.selection_single(\n    fields=[\"date\"],\n    nearest=True,\n    on=\"mouseover\",\n    empty=\"none\",\n    clear=\"mouseout\",\n)\n\ntooltips = alt.Chart(cat_index_dict['category_3'][mask].reset_index()).transform_pivot(\n    \"category_3\", \"index\", groupby=[\"date\"]\n).mark_rule(strokeWidth=2, color=\"grey\").encode(\n    x='date:T',\n    opacity=alt.condition(hover, alt.value(0.75), alt.value(0)),\n    tooltip=[\"date:T\"]+[alt.Tooltip(f\"{cat_1}:Q\", format='.2f') for cat_1 in cat_index_dict['category_3'][mask]['category_3'].unique()],\n).add_selection(hover)\n\n\n(base + tooltips).configure_title(\n    fontSize=17\n).configure_axis(\n    labelFontSize=13,\n    titleFontSize=15\n).configure_legend(\ntitleFontSize=14,\nlabelFontSize=13\n)"
  },
  {
    "objectID": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-frozen-food-subcategories",
    "href": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-frozen-food-subcategories",
    "title": "solverism-quarto-blog",
    "section": "Price Changes for Frozen Food Subcategories",
    "text": "Price Changes for Frozen Food Subcategories\n\n# hide_input\n\nprimary_cat = 'frozen-food'\nmask = cat_index_dict['category_2']['category_1'] == primary_cat\n\nselection = alt.selection_multi(fields=['category_2'], bind='legend')\n\nbase = alt.Chart(cat_index_dict['category_2'][mask].reset_index()).mark_line().encode(\n    y=alt.Y(shorthand='index', scale=alt.Scale(zero=False), axis=alt.Axis(title='Index')),\n    x=alt.X(shorthand='date', axis=alt.Axis(title='Week Commencing Monday')),\n    color=alt.Color('category_2', legend=alt.Legend(title=f\"{' '.join(primary_cat.split('-')).title()} Subcategory\")),\n    strokeDash='category_2',\n    opacity=alt.condition(selection, alt.value(1), alt.value(0.2))\n).add_selection(\n    selection\n).properties(\n    title=f\"Index of Tesco Food Subcategories for {' '.join(primary_cat.split('-')).title()} Category\",\n    width=800,\n    height=500\n)\n\nhover = alt.selection_single(\n    fields=[\"date\"],\n    nearest=True,\n    on=\"mouseover\",\n    empty=\"none\",\n    clear=\"mouseout\",\n)\n\ntooltips = alt.Chart(cat_index_dict['category_2'][mask].reset_index()).transform_pivot(\n    \"category_2\", \"index\", groupby=[\"date\"]\n).mark_rule(strokeWidth=2, color=\"grey\").encode(\n    x='date:T',\n    opacity=alt.condition(hover, alt.value(0.75), alt.value(0)),\n    tooltip=[\"date:T\"]+[alt.Tooltip(f\"{cat_1}:Q\", format='.2f') for cat_1 in cat_index_dict['category_2'][mask]['category_2'].unique()],\n).add_selection(hover)\n\n\n(base + tooltips).configure_title(\n    fontSize=17\n).configure_axis(\n    labelFontSize=13,\n    titleFontSize=15\n).configure_legend(\ntitleFontSize=14,\nlabelFontSize=13\n)"
  },
  {
    "objectID": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-food-cupboard-subcategories",
    "href": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-food-cupboard-subcategories",
    "title": "solverism-quarto-blog",
    "section": "Price Changes for Food Cupboard Subcategories",
    "text": "Price Changes for Food Cupboard Subcategories\n\n# hide_input\n\nprimary_cat = 'food-cupboard'\nmask = cat_index_dict['category_2']['category_1'] == primary_cat\n\nselection = alt.selection_multi(fields=['category_2'], bind='legend')\n\nbase = alt.Chart(cat_index_dict['category_2'][mask].reset_index()).mark_line().encode(\n    y=alt.Y(shorthand='index', scale=alt.Scale(zero=False), axis=alt.Axis(title='Index')),\n    x=alt.X(shorthand='date', axis=alt.Axis(title='Week Commencing Monday')),\n    color=alt.Color('category_2', legend=alt.Legend(title=f\"{' '.join(primary_cat.split('-')).title()} Subcategory\")),\n    strokeDash='category_2',\n    opacity=alt.condition(selection, alt.value(1), alt.value(0.2))\n).add_selection(\n    selection\n).properties(\n    title=f\"Index of Tesco Food Subcategories for {' '.join(primary_cat.split('-')).title()} Category\",\n    width=800,\n    height=500\n)\n\nhover = alt.selection_single(\n    fields=[\"date\"],\n    nearest=True,\n    on=\"mouseover\",\n    empty=\"none\",\n    clear=\"mouseout\",\n)\n\ntooltips = alt.Chart(cat_index_dict['category_2'][mask].reset_index()).transform_pivot(\n    \"category_2\", \"index\", groupby=[\"date\"]\n).mark_rule(strokeWidth=2, color=\"grey\").encode(\n    x='date:T',\n    opacity=alt.condition(hover, alt.value(0.75), alt.value(0)),\n    tooltip=[\"date:T\"]+[alt.Tooltip(f\"{cat_1}:Q\", format='.2f') for cat_1 in cat_index_dict['category_2'][mask]['category_2'].unique()],\n).add_selection(hover)\n\n\n(base + tooltips).configure_title(\n    fontSize=17\n).configure_axis(\n    labelFontSize=13,\n    titleFontSize=15\n).configure_legend(\ntitleFontSize=14,\nlabelFontSize=13\n)"
  },
  {
    "objectID": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-drinks-subcategories",
    "href": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-drinks-subcategories",
    "title": "solverism-quarto-blog",
    "section": "Price Changes for Drinks Subcategories",
    "text": "Price Changes for Drinks Subcategories\n\n# hide_input\n\nprimary_cat = 'drinks'\nmask = cat_index_dict['category_2']['category_1'] == primary_cat\n\nselection = alt.selection_multi(fields=['category_2'], bind='legend')\n\nbase = alt.Chart(cat_index_dict['category_2'][mask].reset_index()).mark_line().encode(\n    y=alt.Y(shorthand='index', scale=alt.Scale(zero=False), axis=alt.Axis(title='Index')),\n    x=alt.X(shorthand='date', axis=alt.Axis(title='Week Commencing Monday')),\n    color=alt.Color('category_2', legend=alt.Legend(title=f\"{' '.join(primary_cat.split('-')).title()} Subcategory\")),\n    strokeDash='category_2',\n    opacity=alt.condition(selection, alt.value(1), alt.value(0.2))\n).add_selection(\n    selection\n).properties(\n    title=f\"Index of Tesco Food Subcategories for {' '.join(primary_cat.split('-')).title()} Category\",\n    width=800,\n    height=500\n)\n\nhover = alt.selection_single(\n    fields=[\"date\"],\n    nearest=True,\n    on=\"mouseover\",\n    empty=\"none\",\n    clear=\"mouseout\",\n)\n\ntooltips = alt.Chart(cat_index_dict['category_2'][mask].reset_index()).transform_pivot(\n    \"category_2\", \"index\", groupby=[\"date\"]\n).mark_rule(strokeWidth=2, color=\"grey\").encode(\n    x='date:T',\n    opacity=alt.condition(hover, alt.value(0.75), alt.value(0)),\n    tooltip=[\"date:T\"]+[alt.Tooltip(f\"{cat_1}:Q\", format='.2f') for cat_1 in cat_index_dict['category_2'][mask]['category_2'].unique()],\n).add_selection(hover)\n\n\n(base + tooltips).configure_title(\n    fontSize=17\n).configure_axis(\n    labelFontSize=13,\n    titleFontSize=15\n).configure_legend(\ntitleFontSize=14,\nlabelFontSize=13\n)"
  },
  {
    "objectID": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-bakery-subcategories",
    "href": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-bakery-subcategories",
    "title": "solverism-quarto-blog",
    "section": "Price Changes for Bakery Subcategories",
    "text": "Price Changes for Bakery Subcategories\n\n# hide_input\n\nprimary_cat = 'bakery'\nmask = cat_index_dict['category_2']['category_1'] == primary_cat\n\nselection = alt.selection_multi(fields=['category_2'], bind='legend')\n\nbase = alt.Chart(cat_index_dict['category_2'][mask].reset_index()).mark_line().encode(\n    y=alt.Y(shorthand='index', scale=alt.Scale(zero=False), axis=alt.Axis(title='Index')),\n    x=alt.X(shorthand='date', axis=alt.Axis(title='Week Commencing Monday')),\n    color=alt.Color('category_2', legend=alt.Legend(title=f\"{' '.join(primary_cat.split('-')).title()} Subcategory\")),\n    strokeDash='category_2',\n    opacity=alt.condition(selection, alt.value(1), alt.value(0.2))\n).add_selection(\n    selection\n).properties(\n    title=f\"Index of Tesco Food Subcategories for {' '.join(primary_cat.split('-')).title()} Category\",\n    width=800,\n    height=500\n)\n\nhover = alt.selection_single(\n    fields=[\"date\"],\n    nearest=True,\n    on=\"mouseover\",\n    empty=\"none\",\n    clear=\"mouseout\",\n)\n\ntooltips = alt.Chart(cat_index_dict['category_2'][mask].reset_index()).transform_pivot(\n    \"category_2\", \"index\", groupby=[\"date\"]\n).mark_rule(strokeWidth=2, color=\"grey\").encode(\n    x='date:T',\n    opacity=alt.condition(hover, alt.value(0.75), alt.value(0)),\n    tooltip=[\"date:T\"]+[alt.Tooltip(f\"{cat_1}:Q\", format='.2f') for cat_1 in cat_index_dict['category_2'][mask]['category_2'].unique()],\n).add_selection(hover)\n\n\n(base + tooltips).configure_title(\n    fontSize=17\n).configure_axis(\n    labelFontSize=13,\n    titleFontSize=15\n).configure_legend(\ntitleFontSize=14,\nlabelFontSize=13\n)"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Since this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  }
]