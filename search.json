[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Brandon Lee",
    "section": "",
    "text": "I’m a huge believer of being a life time learner where the learning doesn’t stop once you’ve reached a certain career goal. No, I believe learning should be thought of as a tool that will allow you to become the best version of yourself. A tool that allows you to be constantly honed and sharpened, ready to face any challenges that face your way - be it personal or professional.\nWhen I’m not trying to preach my life philosophy to strangers online, I’m usually building, tinkering with, or thinking of new ideas for data science projects in my free time. These usually start with a small idea but can somehow grow to multiple fully-fledged projects. More often than not, they come about because I want to put some new skills or concepts I’ve learned on client projects into practice. Outside of data science, I’m also pretty passionate about physical fitness.\nHopefully you’ll learn a thing or two from visiting my blog, enjoy your stay and feel free to connect on LinkedIn or send me a message!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Solverism",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n\n\n\n\n  \n\n\n\n\n\n\n\n\nJoin me as I dig out insights from the Spotify metadata of my playlists and attempt to identify clusters of similar tracks.\n\n\n\n\n\n\nDec 27, 2022\n\n\n22 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nMeasuring food price inflation in a way that anyone in the UK can relate to.\n\n\n\n\n\n\nSep 20, 2022\n\n\n12 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2022-09-20-tesco-price-analysis.html",
    "href": "posts/2022-09-20-tesco-price-analysis.html",
    "title": "Looking into food price inflation using data from Tesco",
    "section": "",
    "text": "Source: https://www.rte.ie/news/business/2022/0908/1321302-cso-inflation-figures/\nDisclaimer: The use of data collected for this study is covered by the Intellectual Property Office’s Exceptions to Copyright for Non-Commercial Research and Private Study. No personal information has been collected as part of this study’s data collection process and web scraping best practices implemented to the best of the author’s abilities. The collected data will be inaccessible to the public to abide by Section 7 of the Terms and Conditions agreement laid out by Tesco PLC.\nSince July 2021 the Consumer Prices Index (CPI) inflation rate in the UK has broken away from the Bank of England’s target rate of 2%, steadily rising month by month. As of 3rd September 2022, the inflation rate stands at 10.1% with no indication of decreasing. What an awfully depressing way to start a blog post but unfortunately this is the reality that we are all currently facing in the UK. Every month the Office for National Statistics (ONS) calculates CPI by collecting the prices for a basket of around 730 different consumer goods and services that is a representation of the society’s current buying habits and measures the average change in price of the basket on a year-over-year basis. At a risk of grossly simplifying, CPI tells us how much prices in general have changed over the last 12 months.\nThat’s all nice and well but society’s buying habits doesn’t necessarily reflect my buying habits. There are 12 broad categories of goods and services in the CPI basket, some of these categories such as clothing and footwear, and furniture and household goods don’t apply to me as I rarely ever buy new clothes or furniture. The full list of categories and goods and services of each category can be found on the ONS website here. One category that does apply to me, and to everyone else, is food and drinks. Food and drink goods (excluding alcohol) currently account for 9.3% of the weighting in CPI, which is a relatively small slice of the pie.\nDuring recent times I’ve noticed that my shopping bill has gone up overall but I can’t quite pin down what items are contributing the most to this increase. To this end, I’ve built a cloud-based web-scraping application that scrapes product data from Tesco’s website including price and categories (GitHub link - blog article incoming). The reason why I chose Tesco as opposed to any other supermarket is because it’s 5 minutes down the road from me.\nIn this article we’ll load, process, transform, and analyse this scraped data to see how the prices of food categories have changed over time. If you want to skip directly to the charts and analysis, head to the ‘Charts and Analysis’ section in the above table of contents."
  },
  {
    "objectID": "posts/2022-09-20-tesco-price-analysis.html#overview-of-price-changes-for-all-categories",
    "href": "posts/2022-09-20-tesco-price-analysis.html#overview-of-price-changes-for-all-categories",
    "title": "Looking into food price inflation using data from Tesco",
    "section": "Overview of Price Changes for All Categories",
    "text": "Overview of Price Changes for All Categories\nLet’s start with the big picture (quite literally), how did prices change when comparing the basket values of categories?\n\n\n\n\n\n\nThis chart is interactive!\n\n\n\nHover your mouse over the sector to look at the index number of categories (if on mobile, tap and hold the name of the category). Clicking on a sector will focus on that particular category and its subcategories. There are 4 levels of categories but only 3 levels are shown at any one time for better performance.\n\n\n\n\n\n\n\n\nThe index numbers presented in the graph below are accurate when rounding to whole numbers!\n\n\n\n\n\nTechnical explanation - The numbers get more inaccurate as you go up category granularities due to the way that the index numbers are aggregated. I’m using the most granular dataset that contains index numbers of quaternary categories, these are then aggregated up to the tertiary category level using the harmonic mean weighted by the basket value of the quaternary categories within the tertiary category. This process repeats for the secondary and then the primary categories, the approximation error increasing going up with each category level.\n\n\n\n\n\n\n                                                \n\n\nStraight away we can see that fresh food and frozen food have increased by ~3% and ~4% respectively. The major contributing subcategories for fresh food are cheese (~5% increase); fresh meat and poultry (~5% increase); ready meals (~4% increase); and yogurts (~4% increase). For frozen food, the major contributing subcategories are frozen fish and seafood (~9% increase); frozen chips, onion rings, potatoes, and rice (~12% increase); and frozen meat and poultry (~5% increase).\nYikes, no wonder why my shopping bill has been going up. Fresh chicken breast and thighs have gone up by over 10%!\nOverall, prices have by 1.7% across all categories and products in the processed dataset.\nWe can also see there are a few secondary categories that have gone down, most notably is the cooking sauces, meal kits, and sides subcategory within the food cupboard category which has gone down by ~2%. This does raise another question though, how many categories in each level experienced an increase, decrease, or no change in price?\n\n\n\n\n\n\n\nIt’s very clear from the above that the bakery and frozen food primary categories had all secondary, tertiary, and quaternary subcategories either increase in price or stay the same! We’ll have to note that they’re the two smallest primary categories by both total basket value and number of subcategories, but there are ongoing macroeconomic events that are affecting both the supply chain and cost of businesses.\nAs of writing, the 2022 Russian invasion of Ukraine is affecting the two largest global suppliers of wheat. Russia produces 11% of the world’s wheat and accounts for 19% of global wheat exports. On the other hand, Ukraine produces 3% of the world’s wheat and accounts for 9% of global wheat exports. Both of these together account for more than a quarter of the world’s wheat export market.1 You can guess what ingredient bakery goods use that’s derived from wheat.1 Source: https://asmith.ucdavis.edu/news/russia-ukraine\nEnergy prices have also been rising throughout 2022 and are forecasted to reach unprecedented levels during the first two quarters of 2023. The electricity price (kWh) cap rose from 20.8p in Q1 2022 to 28.3p in Q2 2022,2 an increase of 36%. This will affect the production costs of all goods, more so if they need to be kept cold or frozen.2 Source: https://www.icaew.com/insights/viewpoints-on-the-news/2022/sept-2022/chart-of-the-week-energy-price-cap-update\nGenerally speaking, it does seem that the vast majority of subcategories have experienced an increase in price, no matter what level of category granularity is being looked at. The drinks and food cupboard primary categories are the least affected as they’re the only two that contain secondary categories that have decreased in price; that being said they only account for 11.1% and 18.8% of the total number of their respective total secondary categories."
  },
  {
    "objectID": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-primary-food-categories",
    "href": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-primary-food-categories",
    "title": "Looking into food price inflation using data from Tesco",
    "section": "Price Changes for Primary Food Categories",
    "text": "Price Changes for Primary Food Categories\nLet’s now take a look at how the index of primary categories changed over time as opposed to a snapshot in time.\n\n\n\n\n\n\n\nThere are a few things I’m seeing from this graph. First is that bakery, drinks, and food cupboard items seem to be plateauing where as fresh and frozen items don’t seem to be slowing down. Second, the fresh and frozen items have the highest rate of increase amongst all primary categories. Third, the food cupboard and drinks categories seem to increase at the same rate were it not for the initial hike on 6th March. Finally, the bakery category is the only one that looks to practically stay the same for the first five weeks before rapidly increasing at the same rate as the fresh and frozen food categories and then plateauing.\nThe big question that comes to mind is what’s driving the price of fresh food items to go up? If we extrapolate out the trend for an entire year, we’re looking at an approximate increase of 12.5% for both categories! To answer this question we’ll have to dive into the secondary categories."
  },
  {
    "objectID": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-fresh-food-subcategories",
    "href": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-fresh-food-subcategories",
    "title": "Looking into food price inflation using data from Tesco",
    "section": "Price Changes for Fresh Food Subcategories",
    "text": "Price Changes for Fresh Food Subcategories\n\n\n\n\n\n\n\n\nWow there’s a lot going on in that graph, but can definitely be seen that some secondary categories are increasing much more than others. Let’s take a look at the index values at the end of the graph to quickly look at which secondary categories increased the most.\n\n\n\n\n\n\n  \n    \n      \n      Week Commencing Monday\n      Primary Category\n      Secondary Category\n      Total Basket Value (£)\n      Index\n    \n  \n  \n    \n      0\n      2022-06-13\n      fresh-food\n      cheese\n      543.92\n      104.73\n    \n    \n      1\n      2022-06-13\n      fresh-food\n      fresh-meat-and-poultry\n      1311.26\n      104.72\n    \n    \n      2\n      2022-06-13\n      fresh-food\n      yoghurts\n      389.49\n      104.13\n    \n    \n      3\n      2022-06-13\n      fresh-food\n      cooked-meats-antipasti-and-dips\n      537.09\n      103.95\n    \n    \n      4\n      2022-06-13\n      fresh-food\n      chilled-fish-and-seafood\n      270.53\n      103.56\n    \n    \n      5\n      2022-06-13\n      fresh-food\n      milk-butter-and-eggs\n      324.88\n      103.14\n    \n    \n      6\n      2022-06-13\n      fresh-food\n      ready-meals\n      653.29\n      102.98\n    \n    \n      7\n      2022-06-13\n      fresh-food\n      pies-pasties-quiches-and-snacking\n      322.31\n      102.83\n    \n    \n      8\n      2022-06-13\n      fresh-food\n      fresh-salad-coleslaw-and-sandwich-fillers\n      152.96\n      102.35\n    \n    \n      9\n      2022-06-13\n      fresh-food\n      chilled-vegetarian-and-vegan\n      290.60\n      102.29\n    \n    \n      10\n      2022-06-13\n      fresh-food\n      chilled-soup-sandwiches-and-salad-pots\n      226.00\n      101.87\n    \n    \n      11\n      2022-06-13\n      fresh-food\n      dairy-free-and-dairy-alternatives\n      328.15\n      101.85\n    \n    \n      12\n      2022-06-13\n      fresh-food\n      chilled-desserts\n      275.90\n      101.80\n    \n    \n      13\n      2022-06-13\n      fresh-food\n      fresh-vegetables\n      164.09\n      101.74\n    \n    \n      14\n      2022-06-13\n      fresh-food\n      juice-and-smoothies\n      44.01\n      100.62\n    \n    \n      15\n      2022-06-13\n      fresh-food\n      fresh-pizza-pasta-and-garlic-bread\n      292.38\n      100.30\n    \n    \n      16\n      2022-06-13\n      fresh-food\n      counters\n      100.25\n      100.10\n    \n    \n      17\n      2022-06-13\n      fresh-food\n      fresh-fruit\n      239.01\n      100.10\n    \n  \n\n\n\n\nLooking at the top 6 rows, it’s primarily dairy and fresh meat and poultry that’s driving up the index of fresh food items. Both of these being products produced from animals.\nAccording to the Specialty Food Magazine, the price increase of dairy products can be largely attributed to the spiralling price of feed, fuel, and fertiliser.3 All of these three production costs have been subject to large price hikes. For feed and fertiliser, it can be attributed to the Russian invasion on Ukraine, higher energy costs, and increased global demand.4 For fuel, the primary driver is an increase in the refining cost of crude oil.53 Source: https://www.specialityfoodmagazine.com/news/dairy-crisis-threatens-spiralling-costs-of-cheese-and-milk-for-indies4 Source: https://lordslibrary.parliament.uk/rising-cost-of-agricultural-fertiliser-and-feed-causes-impacts-and-government-policy/5 Source: https://www.allstarcard.co.uk/news-insights/business/why-is-fuel-expensive/\nIn Specialty Food Magazine’s article they have a quote from the vice-chair of the National Union of Farmers that it takes him two and a half years to get a cow from being born to be actually producing milk which incurs a lot of cost over the time period. In order to maintain their profit margins, they must raise their prices."
  },
  {
    "objectID": "posts/2022-09-20-tesco-price-analysis.html#correlation-heatmap-of-all-secondary-categories",
    "href": "posts/2022-09-20-tesco-price-analysis.html#correlation-heatmap-of-all-secondary-categories",
    "title": "Looking into food price inflation using data from Tesco",
    "section": "Correlation Heatmap of All Secondary Categories",
    "text": "Correlation Heatmap of All Secondary Categories\nNote that the below graph is using Pearson’s Correlation coefficient. When the index of two subcategories move in tandem (i.e. they’ve got a positive correlation) the rectange will show as red, the stronger the correlation the more red the rectangle will be. Similar logic applies for when two subcategories move in opposite directions, except with blue. Interesting observation that the adult soft drink and mixers subcategory (first row/column) isn’t showing much of a correlation with anything else."
  },
  {
    "objectID": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-fresh-meat-and-poultry-subcategories",
    "href": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-fresh-meat-and-poultry-subcategories",
    "title": "Looking into food price inflation using data from Tesco",
    "section": "Price Changes for Fresh Meat and Poultry Subcategories",
    "text": "Price Changes for Fresh Meat and Poultry Subcategories"
  },
  {
    "objectID": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-cheese-subcategories",
    "href": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-cheese-subcategories",
    "title": "Looking into food price inflation using data from Tesco",
    "section": "Price Changes for Cheese Subcategories",
    "text": "Price Changes for Cheese Subcategories"
  },
  {
    "objectID": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-frozen-food-subcategories",
    "href": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-frozen-food-subcategories",
    "title": "Looking into food price inflation using data from Tesco",
    "section": "Price Changes for Frozen Food Subcategories",
    "text": "Price Changes for Frozen Food Subcategories"
  },
  {
    "objectID": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-food-cupboard-subcategories",
    "href": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-food-cupboard-subcategories",
    "title": "Looking into food price inflation using data from Tesco",
    "section": "Price Changes for Food Cupboard Subcategories",
    "text": "Price Changes for Food Cupboard Subcategories"
  },
  {
    "objectID": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-drinks-subcategories",
    "href": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-drinks-subcategories",
    "title": "Looking into food price inflation using data from Tesco",
    "section": "Price Changes for Drinks Subcategories",
    "text": "Price Changes for Drinks Subcategories"
  },
  {
    "objectID": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-bakery-subcategories",
    "href": "posts/2022-09-20-tesco-price-analysis.html#price-changes-for-bakery-subcategories",
    "title": "Looking into food price inflation using data from Tesco",
    "section": "Price Changes for Bakery Subcategories",
    "text": "Price Changes for Bakery Subcategories"
  },
  {
    "objectID": "posts/2022-10-21-spotify.html",
    "href": "posts/2022-10-21-spotify.html",
    "title": "A deep dive into Spotify audio features",
    "section": "",
    "text": "Source: https://techcrunch.com/2020/06/29/in-a-significant-expansion-spotify-to-launch-real-time-lyrics-in-26-markets/\nI’ve been a user of Spotify now since 2017 and during that time I’ve created a myriad of playlists, most of which I’m willing to admit I haven’t touched in a long time. Generally speaking, my playlists fall into one of four categories.\nFirst, and most predominantly, is based on time. I create bimonthly playlists in which I add songs I’ve enjoyed throughout the two months, at the end of the year I’ll compile all 6 of those into a yearly round-up playlist. Second is based on music genre, I have playlists for each genre I listen to (of course there’s bound to be a bit of overlap). Third is based on language, I listen to a mixture of English, Japanese, Korean, and Cantonese songs. Fourth, and finally, are playlists created from song radios or other Spotify-generated means.\nOne thing that you might not know about Spotify is that it has an API that can be used by developers to create Spotify apps. It’s called the Spotify Web API and it allows you to control audio playback, manage your Spotify library, get metadata of tracks, artists, and albums, and so much more. I’m utilising the Spotipy Python library to use it. For my purposes I’ll be using it to get my playlists’ metadata and the audio features of tracks.\nIn this blog we’ll be going on a journey that explores my playlists in a data-driven way and eventually produce a machine learning algorithm that gives the most similar tracks in my playlists when provided with a track. All plots, where possible, will be made using Plotly (which is natively interactively) so hover over them, click on them, and drag around on them - see what happens!"
  },
  {
    "objectID": "posts/2022-10-21-spotify.html#data-dictionary",
    "href": "posts/2022-10-21-spotify.html#data-dictionary",
    "title": "A deep dive into Spotify audio features",
    "section": "Data Dictionary",
    "text": "Data Dictionary\nYou might be looking at some of those column names with no idea what they mean or represent, luckily Spotify does provide explanations for their audio features. And even luckier for you, I’ve created a data dictionary that describes what each column represents. Note, the language column was created used my language playlists and the genre column was created using data from Every Noise at Once.\n\n\n\n\n\n\n\n\n\nColumn\nCategory\nDescription\n\n\n\n\nname\nTrack Property\nName of the track.\n\n\nartist\nTrack Property\nName of the artist.\n\n\npopularity\nArtist Property\nThe popularity of the artist. The value will be between 0 and 100, with 100 being the most popular. The artist’s popularity is calculated from the popularity of all the artist’s tracks.\n\n\nplaylist_name\nTrack Property\nName of playlist in which this track resides.\n\n\nplaylist_date_added\nTrack Property\nDate and time when the track was added to playlist.\n\n\ndanceability\nMood\nDanceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.\n\n\nenergy\nMood\nEnergy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.\n\n\nloudness\nTrack Property\nThe overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typically range between -60 and 0 db.\n\n\nspeechiness\nTrack Property\nSpeechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words.\n\n\nacousticness\nContext\nA confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.\n\n\ninstrumentalness\nTrack Property\nPredicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content.\n\n\nliveness\nContext\nDetects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.\n\n\nvalence\nMood\nA measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n\n\ntempo\nMood\nThe overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.\n\n\nlang_jap\nLanguage\nWhether the track features Japanese language, binary value of 0 or 1.\n\n\nlang_kor\nLanguage\nWhether the track features Korean language, binary value of 0 or 1.\n\n\nlang_can\nLanguage\nWhether the track features Cantonese language, binary value of 0 or 1.\n\n\nlang_eng\nLanguage\nIf a track doesn’t feature Japanese, Korean, or Cantonese it’s assumed to be English. Binary value of 0 or 1.\n\n\npop\nGenre\nBinary value that describes whether a track’s artist is labelled as pop.\n\n\nrock\nGenre\nBinary value that describes whether a track’s artist is labelled as rock.\n\n\nhip_hop\nGenre\nBinary value that describes whether a track’s artist is labelled as hip-hop.\n\n\nindie\nGenre\nBinary value that describes whether a track’s artist is labelled as indie.\n\n\nrap\nGenre\nBinary value that describes whether a track’s artist is labelled as rap.\n\n\nalternative\nGenre\nBinary value that describes whether a track’s artist is labelled as alternative."
  },
  {
    "objectID": "posts/2022-10-21-spotify.html#starting-simple-with-univariate-analysis",
    "href": "posts/2022-10-21-spotify.html#starting-simple-with-univariate-analysis",
    "title": "A deep dive into Spotify audio features",
    "section": "Starting Simple with Univariate Analysis",
    "text": "Starting Simple with Univariate Analysis\nIt’s always good to start with simple descriptive analysis to get a feel for the data. Let’s first start by looking at how many tracks are in each playlist.\n\n\n\n                                                \n\n\nClearly 2019 was a good year for music with 973 tracks being added to the ‘2019 Complete Round Up’ throughout the year. That’s 2.7 tracks per day on average! I’m quite picky with the tracks I’ll add to my bimonthly playists, I’d give an estimate of 1 track being added for every 15 tracks listened to - going by that I was listening to about 41 new tracks every day. For some context, 2019 was when I was finishing my master’s degree in Data Science during which I was listening to music while studying.\nLet’s take a look at the distribution of the features in the dataset. For a baseline comparison, I’ve downloaded a Kaggle dataset containing Spotify audio features of more than 580k tracks which has a great deal more than the ~8k tracks in our dataset. It contains tracks released from the 1920s to 2022 across a variety of genres with over 110k unique artists, making it a good baseline to compare statistics.\n\nDanceabilityEnergyValenceTempoLoudnessDurationArtist PopularityGenreLanguage\n\n\nDanceability is commonly defined as how ‘dancable’ a track is and there’s much subjectivity involved in determining this. Spotify has defined it based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.\nThe median value (value in the middle when sorted in ascending order) in our dataset is 0.64 and the middle half of the data (quartile 1 to 3) is between 0.52 and 0.73. To compare with the Kaggle dataset, we can say that, on average, the tracks in my dataset are more danceable than the Kaggle dataset. The mean values between the two datasets are statistically significant at the 0.1% level using Welch’s t-test.\n\n\n\n                                                \n\n\n\n\nEnergy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy.\nThe median value is 0.64 and the middle half of the data (quartile 1 to 3) is between 0.49 and 0.79. If you were to pick a random song from all of the above playlists pooled together, there’s a good chance it’s got a decent level of energy (decent being defined as 0.55 and above, the median value from the Kaggle dataset). The mean values between the two datasets are statistically significant at the 0.1% level using Welch’s t-test.\nInterestingly, the distribution seems as if it’s been right censored due to the upper bound of 1.\n\n\n\n                                                \n\n\n\n\nValence is a measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. High valence means more positive sounding (happy, cheerful, etc.) while low valence sounds more negative (sad, angry, etc.)\nThis is an interesting distribution, the median lies pretty much exactly in the middle with a value of 0.4995. The middle half of the data has lies between 0.333 and 0.687 which pretty much covers the middle third of the bounds. In essence, this is telling me that half my tracks are neutral, one quarter are sad/angry/depressed sounding (have a value of below 0.333), and one quarter are happy/cheerful/euphoric sounding (have a value of above 0.687).\nComparing medians with the Kaggle dataset, it does seem that my tracks are on average a little less positive sounding. The mean values between the two datasets are statistically significant at the 0.1% level using Welch’s t-test.\n\n\n\n                                                \n\n\n\n\nThis feature represents the overall estimated tempo of a track in beats per minute (BPM).\nThe median BPM of tracks is about 120 BPM with 50% of tracks being between 98 and 140 BPM. This almost exactly aligns with an article from MasterClass that states: “Most of today’s popular songs are written in a tempo range of 100 to 140 BPM”.\nComparing with the medians Kaggle dataset we find that the two are very close (120 BPM vs 117 BMP). The mean values between the two datasets are also statistically significant at the 0.1% level using Welch’s t-test.\nHaven’t got too much to say about this, it makes sense that there will be a lower-bound BPM threshold that most tracks will be above and conversely an upper-bound threshold that most tracks will be below. I’d imagine this distribution would drastically change if someone were to exclusively listen to EDM, Techno, or similar high-tempo genres.\n\n\n\n                                                \n\n\n\n\nThe overall loudness of a track in decibels (dB). This looks like a textbook example of a left (or negative) skewed distribution. It does seem that, on average, the tracks in my dataset are louder than the ones in the Kaggle dataset (-6.6 dB vs -9.2 dB). Additionally, the mean values between the two datasets are statistically significant at the 0.1% level using Welch’s t-test.\nI don’t know enough about decibels in the context of music mixing and mastering (or any context for that matter) to meaningfully comment on this.\n\n\n\n                                                \n\n\n\n\nHere we’ve got the distribution of track durations in seconds. This looks like a normal-ish distribution with a long tail on the right (we can test to see how close it is to a normal distribution using a Q-Q plot but I’ll skip that here).\nWhat we can get from this is that the median track length is 3 minutes and 45 seconds and half of the tracks have a duration between 3 minutes and 11 seconds and 4 minutes and 19 seconds. I’ve got one track on the very far right that has a duration of 13 minutes and 44 seconds.\nComparing with the Kaggle dataset we find that the median track durations are very similar (3 minutes and 35 seconds for Kaggle). When performing Welch’s t-test, we cannot reject the null hypothesis that the two means are the same at the 1% significance level.\n\n\n\n                                                \n\n\n\n\nSpotify has a measure for the populary of an artist which will be between 0 and 100, with 100 being the most popular. The artist’s popularity is calculated from the popularity of all the artist’s tracks.\nI’ve de-duplicated the data based on artists so we’ll have one row (track) per artist to see the distribution of artist popularity. Not-so-surprisingly about 33% of the artists I listen to have a popularity value of 0. Those look to be artists/bands with small followings.\nDoing the same for the Kaggle dataset, we find that only 9% of artists have a popularity of 0. On average, tracks from my dataset are less popular than the ones from the Kaggle dataset (26 vs 35). Given that the distribution is non-Gaussian, it isn’t appropriate to use Welch’s t-test to test whether the means are the same between the two datasets. It’s more appropriate to use the Mann-Whitney U test which tells us that the distributions of the two are not identical at the 0.1% significance level.\n\n\n\n                                                \n\n\n\n\nGenre is a bit of a funny one since it’s not representing the genre(s) of the track, but rather the genre(s) of the track’s artist. While this isn’t perfect, it does act as a good enough proxy for our purposes. Note that a track’s artist can be assigned more than one genre.\nAt first glance it does seem like Pop is the most common genre but I think it needs to be remembered that Pop is probably the most paired/combined genre (e.g. Pop Rock or Indie Pop).\n\n\n\n                                                \n\n\n\n\nUnfortunately Spotify’s API doesn’t provide any metadata on the language of a track. Luckily I have language based playlists, and from that I can say any tracks that aren’t in those playlists are English tracks. That probably works for let’s say 85-90% of them."
  },
  {
    "objectID": "posts/2022-10-21-spotify.html#moving-to-two-dimensions-with-bivariate-analysis",
    "href": "posts/2022-10-21-spotify.html#moving-to-two-dimensions-with-bivariate-analysis",
    "title": "A deep dive into Spotify audio features",
    "section": "Moving to Two Dimensions with Bivariate Analysis",
    "text": "Moving to Two Dimensions with Bivariate Analysis\n\nCorrelation Analysis\nWhile we managed to learn about the features individually in the analysis above, we didn’t touch on the relationship between two features (if there is even a relationship). One way we can compactly visualise whether pairings of features have a relationship is to construct an N×N correlation matrix where N is the number of features.\nThere are several different measures that can be used to calculate the correlation between two variables, the de facto standard is Pearson’s correlation coefficient which measures the strength and direction of the linear relationship between two continuous variables. Another measure is Spearman’s rank correlation coefficient which is a nonparametric measure of rank correlation; in other words, it measures the correlation between the rankings of two variables (a good visual example of this is on its Wikipedia page). Unlike Pearson’s r, Spearmans’ ρ can be used to assess monotonic relationships (linear relationships are a subset of these) for both continuous and discrete ordinal (ranked order) variables.\nVery recently, in March 2019, a new measure of correlation was unveiled that is able both capture non-linear dependencies and work consistently between categorical, ordinal, and continuous variables. It is named 𝜙K (PhiK) and the technical details, alongside a few practical examples, are found in its paper. Unlike both Pearson’s r and Spearman’s ρ, 𝜙K is bounded between 0 and 1 which tells us the strength but not the direction of a relationship. This is because direction isn’t well-defined for a non-monotonic relationship, as you’ll see below.\nI’ve created a graph below to compare the three correlation coefficients on synthetic datasets (which is based on the first image from Wikipedia’s page on Correlation). As you can see, the last two rows of charts are all non-linear relationships between x and y which, as expected, result in a correlation coefficient value of zero for both Pearson’s r and Spearman’s ρ. On the other hand, 𝜙K is able to identify these relationships and the values produced are statistically significant at the 0.1% level. Exciting stuff!\n\n\n\n\n\n\nP-values are in the brackets next to the calculated correlation coefficient values, this is used to determine whether the values are statistically significant or not at a pre-defined significance level.\n\n\n\n\n\n\n\n\n\n\n\n\nThe ρ in ‘True ρ’ in the first row of charts represents the population Pearson correlation coefficient and not Spearman’s ρ.\n\n\n\nFor a sample of data from the population, r is used instead of ρ and is referred to as the sample Pearson correlation coefficient.\n\n\n\n\n\n                                                \n\n\nArmed with these tools, let’s go ahead and use them to create correlation matrices for the Spotify audio features.\n\nPearson’s rSpearman’s ρ𝜙K\n\n\n\n\n\n                                                \n\n\n\n\n\n\n\n                                                \n\n\n\n\n\n\n\n                                                \n\n\n\n\n\nThere’s not much of a difference when comparing the Pearson and Spearman correlation matrices but looking at the 𝜙K matrix unveils a non-linear relationship between tempo and danceability that wasn’t captured by the first two measures. I’ve made a table below that pick out pairs of features with an absolute correlation value of 0.5 or above for any of the three measures.\n\n\n\n\n\n\n  \n    \n      \n      Feature 1\n      Feature 2\n      PhiK\n      Pearson\n      Spearman\n    \n  \n  \n    \n      1\n      energy\n      loudness\n      0.80\n      0.78\n      0.77\n    \n    \n      2\n      energy\n      acousticness\n      0.67\n      -0.62\n      -0.62\n    \n    \n      3\n      loudness\n      acousticness\n      0.56\n      -0.52\n      -0.50\n    \n    \n      0\n      danceability\n      tempo\n      0.51\n      -0.22\n      -0.16\n    \n  \n\n\n\n\nA thing to keep in mind is that these are summary statistics, to get the full picture we need to take a look at the scatterplot of feature pairs.\n\nEnergy vs LoudnessEnergy vs AcousticnessLoudness vs AcousticnessDanceability vs Tempo\n\n\nThere’s a strong positive and almost linear correlation between energy and loudness which makes sense because energy measures the intensity of a track and loud tracks can be thought to be of as more intense. Note that energy is a measure that’s calculated by Spotify so there’s a good chance that it’s a function of loudness and some other track properties.\n\n\n\n                                                \n\n\n\n\nThere seems to be a moderate negative correlation between the energy of a track and the confidence of whether a track is acoustic. Acoustic music is music that mainly uses unamplified instruments that produce sound only by acoustic means. This means no eletric or virtual instruments. As you can imagine, acoustic tracks would have a lower energy compared to tracks that utilise electric or electronic instruments, so this correlation makes sense to me.\n\n\n\n                                                \n\n\n\n\nSimilar logic for the correlation between energy and acousticness applies here.\n\n\n\n                                                \n\n\n\n\nThis one is an interesting one. Going by the LOWESS (Locally Weighted Scatterplot Smoothing) trendline, there seems to be sweet-spot in tempo where the most danceable tracks are. Going back to the definition of danceability, it’s calculated based on a combination of tempo, rhythm stability, beat strength, and overall regularity. We know that there’s a definitive relationship between the two variables, and from the below chart we can clearly see it’s a non-linear relationship.\n\n\n\n                                                \n\n\n\n\n\n\n\nAnalysis by Time, Playlist, and Genre\nLet’s now analyse the how Spotify audio features change throughout time, how they vary by playlists (only considering the major ones), and whether different genres can be distinguished solely through these features.\n\n\nYearly PlaylistsLanguage and Genre PlaylistsTrack Artist Genre\n\n\nHere we’re looking at how my music taste changes over the years. It’s immediately clear 2022 (up until August) has included more energetic and valent tracks (what I’d like to call ‘positive vibes’) marked by the median values and tighter inter-quartile range.\nI’ve plotted the boxplots with a notch representing the 95% confience interval of the median which offers a rough guide of the significance of the difference of medians; if the notches of two boxes do not overlap, this will provide evidence of a statistically significant difference between the medians. Thus, we can say that there is a statistically significant difference in medians at the 5% level in the medians between 2021 and 2022 for the energy and valence features.\n\n\n\n                                                \n\n\n\n\nLooking at my larger playlists based on language and genre, it’s possible to see distinct characteristic feature profiles of the playlists.\nLet’s take the Upbeat playlist as an example; it’s characterised by tracks with high energy (median 0.88), tempo (median 145 BPM), and loudness (median -5.8 dB). On the other hand, the Chill playlist is characterised by tracks with low energy (median 0.45), valence (median 0.38), tempo (median 111 BPM), and loudness (median -9.8 dB) compared to other playlists.\nUnsurprisingly, the Rap/HipHop/Trap and Pop playlists rank the highest for danceability on average and are tied third for energy. Pop takes a close second for valence, meaning it ranks second for ‘positive vibes’. Surprisingly the Japanese playlist takes second place when considering energy, tracks on average being 27% more ‘energetic’ than tracks in the former two playlists. It also ranks first in both valence and loduness, being the most positive and loud out of the playlists.\n\n\n\n                                                \n\n\n\n\nTurning our attention towards the genre, we want to see if we can identify a characteristic feature profile for the six different genres in our dataset - much like we did with the playlists. Recall that the genres represent the genres of the track’s artists and not the genre of the track. This does mean that the analysis results below are estimates through a proxy.\nAt first glance we can see that instrumentalness, tempo, liveliness and (to a lesser extent) valence do not vary significantly enough to be useful for distinguishing genres.\nThe Hip Hop and Rap genres have near identical feature profiles; this can be partially attributed to a large overlap of tracks in both as 24% of Rap tracks are also labelled as Hip Hop and 36% of Hip Hop tracks are also labelled as Rap. I’m not exactly too sure the other reason without a deep dive into this particular area.\nRock has tracks with the highest energy and loudness and the lowest danceability and acousticness on average; it has a very similar feature profile to the Alternative genre (later on we’ll see there’s significant overlap between these two genres as well).\nFinally we have the Pop and Indie genres, upon closer inspection we can see that these too are also similar in their feature profiles. Interesting how that turned out huh?\n\n\n\n                                                \n\n\n\n\n\n\n\n\nGenre Analysis\nThis is where things will start to get a little wavy. Technically speaking, Indie and Alternative are not genres - they’re more along the lines of a set of ideas and beliefs as opposed to a defined musical style. I’ve chosen to include them as genres because they both capture attributes of a track that cannot be captured by the other genres in the dataset. This will ultimately help with the end goal of creating a model that recommends similar tracks from my playlists given a track.\nTake into consideration that genres are not mutually exclusive. Pop Rock is a fusion genre that combines elements of both the Pop and Rock genres. Indie Pop is a sub-genre of Pop that typically combines guitar pop with a more ‘home-grown’ melody compared to mainstream Pop. Rap Rock is another fusion genre that fuses the heavy guitar riffs associated with Rock tracks with the vocal and instrumental elements of Hip Hop (this is actually a genre, I didn’t make that up). The difference between Hip Hop and Rap can be confusing as well, with many people confusing them to be the same thing.\nSo, the question to answer in this section is, which genres are seen paired the most in our dataset? To answer this question, I’ll be using the Jaccard index (also known as Jaccard similarity coefficient) to see which genres co-occur most frequently. This is typically used as a performance metric in object detection computer vision problems to assess how well the bounding boxes predicted by a model match with the ground-truth, but it’s perfectly applicable in this situation.\nTo calculate the Jaccard index, we simply take the number of tracks which have both genres (e.g., tracks that are both Pop and Rock) and divide that by the number of tracks that are either genre (e.g., total number of all Pop tracks and all Rock tracks).\n\n\n\n\n\nBelow I’ve created a matrix which contains the Jaccard index for each pair of genres. We can see that, from most paired to least paired, the following genres co-occur frequently:\n\nHip Hop and Rap\nAlternative and Rock\nIndie and Rock\nIndie and Pop\nAlternative and Indie\nPop and Rock"
  },
  {
    "objectID": "posts/2022-10-21-spotify.html#more-dimensions",
    "href": "posts/2022-10-21-spotify.html#more-dimensions",
    "title": "A deep dive into Spotify audio features",
    "section": "More Dimensions!",
    "text": "More Dimensions!\nVisualising data beyond two dimensions can result in figures that are information dense. Depending on the objective of the visualisation, this can be either a good or bad thing. In this case, I want to provide you with a figure that you can play around and interact with - the 3D scatter plot chart fulfills this objective nicely.\nBelow I’ve made a 3D plot of danceability, energy, and valence with tempo being used as the colour of the points. Note that all the information in this plot is contained in the previous sections."
  },
  {
    "objectID": "posts/2022-10-21-spotify.html#dimensionality-reduction",
    "href": "posts/2022-10-21-spotify.html#dimensionality-reduction",
    "title": "A deep dive into Spotify audio features",
    "section": "Dimensionality Reduction",
    "text": "Dimensionality Reduction\nWhat if we’d like to visualise a large amount of features at once? It becomes increasingly difficult to add more dimensions in a single graph, though you could employ tricks such as using the size of points as a dimension (think bubble plots), different markers for categories, opacity, etc. Visualising 5 or more dimensions becomes infeasible due to the increasingly information density of the resulting chart.\nSo, what can you do? 2D graphs are the defacto standard when it comes to data visualisation; one idea we can employ is to perform dimensionality reduction to essentially ‘compress’ the information of the dataset down into just two dimensions which we can then use a scatter plot to visualise. There are several different techniques under the dimensionality reduction umbrella, with Principal Component Analysis (PCA), T-distributed Stochastic Neighbor Embedding (t-SNE), and Uniform Manifold Approximation and Projection (UMAP) being a few of the more popular techniques.\nI’ll be using UMAP on our dataset on different feature sets to see how the reduced dataset (known as embeddings) appears, the aim is to find a set of features which allow us to identify clusters of tracks that are similar in attributes. PCA isn’t appropriate to use as it isn’t able to handle categorical variables due to its underlying linearity assumptions and t-SNE is much slower compared to UMAP with the end results being sensitive to the settings used.\n\n\nTrack Audio Features OnlyTrack Audio Features with Language indicatorTrack Audio Features with Language & Genre indicators\n\n\nThere doesn’t seem to be any identifiable clusters using only Spotify audio features; however, it does seem as if there’s a honeycomb-like structure appearing in the 2D embedding.\nTip - hover over the individual data points to see the track name and artist.\n\n\n\n                                                \n\n\n\n\nAdding the langugage indicators separates the embedding out into five distinct clusters, four clusters representing a language but it seems we have an additional small cluster comprised of Japanese and Korean songs interestingly. This is better than only using Spotify track audio features but it puts too much emphasis on languges. We can do better.\n\n\n\n                                                \n\n\n\n\nFinally, let’s add genre indicators into the mix. Doing so results in many small clusters, each of which represents a combination of langugage and genres. Tracks close to one another within a cluster share similar Spotify audio feature values. We’ve achieved our goal of identifying clusters of similar tracks!\nTip - click and drag to zoom into a cluster, double click to reset the figure."
  },
  {
    "objectID": "posts/2022-10-21-spotify.html#conclusion",
    "href": "posts/2022-10-21-spotify.html#conclusion",
    "title": "A deep dive into Spotify audio features",
    "section": "Conclusion",
    "text": "Conclusion"
  }
]